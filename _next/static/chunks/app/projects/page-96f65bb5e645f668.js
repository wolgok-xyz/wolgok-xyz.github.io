(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[893],{325:(e,i,t)=>{"use strict";t.d(i,{default:()=>g});var a=t(5155),n=t(5493),o=t(6766),r=t(6874),s=t.n(r),l=t(3227),c=t(9074),d=t(7580),h=t(3786);let p=[{id:3,title:"Development of Self-Evolutionary Embodied AGI Platform through Real-World Experience",description:"Research on developing artificial general intelligence through embodied interaction with the physical world.",imageUrl:"/images/projects/eagi_obj.png",agency:"IITP",period:"2025.04 - 2029.12",organizations:["KIST","Yonsei Univ","KRM"],link:"/projects/3",details:{budget:"KRW",content:[{title:"Research Objectives",description:"This research aims to enhance artificial intelligence's generalization capabilities through interaction with the physical world. We seek to build theoretical foundations and conduct experimental validation using robots.",imageUrl:"/images/projects/eagi_obj.png"},{title:"Key Research Areas",description:"1. Learning through physical interaction\n2. Building theoretical foundations for generalized intelligence\n3. Developing robotic systems for experimental validation\n4. Research on human-robot interaction",imageUrl:"/images/projects/eagi_key.png"},{title:"Expected Impact",description:"Through this research, we expect to enhance AI's generalization capabilities and validate its applicability in the real physical world. Additionally, we aim to present a new paradigm for human-robot interaction."}]}},{id:2,title:"Omni-reasoning Process and Embodied Intelligence Model",description:"Research on natural and intuitive interaction between humans and robots.",imageUrl:"/images/projects/omni_obj.png",agency:"KIST",period:"2025.01 - 2027.12",organizations:["KIST","Korea Univ"],link:"/projects/2",details:{budget:"0 KRW",content:[{title:"Research Objectives",description:"This research aims to develop a novel omni-reasoning process that enables robots to understand and respond to human intentions naturally. We focus on creating an embodied intelligence model that can process multi-modal information and generate appropriate responses in real-time.",imageUrl:"/images/projects/omni_obj.png"},{title:"Key Research Areas",description:"1. Development of omni-reasoning process for multi-modal understanding\n2. Creation of embodied intelligence model for natural interaction\n3. Implementation of real-time response generation system\n4. Integration of cognitive and physical capabilities in robots",imageUrl:"/images/projects/omni_key.png"},{title:"Expected Impact",description:"This research will contribute to the development of more intuitive and natural human-robot interaction systems. The omni-reasoning process and embodied intelligence model will serve as fundamental technologies for future service robots and assistive devices."}]}},{id:1,title:"Development of Artificial Intelligence for Text-based 3D Movie Generation",description:"Research on advanced robotics and control systems for various applications.",imageUrl:"/images/projects/text3d_obj.png",agency:"IITP",period:"2023.04 - 2025.12",organizations:["KIST","Postech","Hanyang Univ","Illuni"],link:"/projects/1",details:{budget:"0 KRW",content:[{title:"Research Objectives",description:"This research aims to develop an AI system that can generate high-quality 3D movies from text descriptions. We focus on creating a comprehensive framework that can understand narrative context, generate appropriate scenes, and produce realistic 3D animations automatically.",imageUrl:"/images/projects/text3d_obj.png"},{title:"Key Research Areas",description:"1. Natural language processing for story understanding\n2. 3D scene generation and composition\n3. Character animation and motion synthesis\n4. Integration of visual effects and sound design",imageUrl:"/images/projects/text3d_key.png"},{title:"Expected Impact",description:"This research will revolutionize the content creation industry by enabling automatic generation of 3D movies from text. The technology will significantly reduce production time and costs while maintaining high quality, making it accessible to a wider range of creators."}]}}];function m(e){let{project:i,index:t}=e;return(0,a.jsxs)(n.P.div,{initial:{opacity:0,y:20},whileInView:{opacity:1,y:0},transition:{duration:.8,delay:.1*t},viewport:{once:!0,margin:"-100px"},className:"group overflow-hidden rounded-lg bg-card shadow-md hover:shadow-lg transition-shadow duration-300",children:[(0,a.jsx)("div",{className:"relative h-48 overflow-hidden bg-white p-8 rounded-lg",children:(0,a.jsx)(o.default,{src:i.imageUrl,alt:i.title,fill:!0,className:"object-cover transition-transform duration-500 group-hover:scale-105 rounded-lg"})}),(0,a.jsxs)("div",{className:"p-6",children:[(0,a.jsxs)("div",{className:"mb-4",children:[(0,a.jsx)("h3",{className:"text-xl font-bold mb-2 group-hover:text-primary transition-colors",children:i.title}),(0,a.jsxs)("div",{className:"flex flex-wrap gap-2 text-xs text-muted-foreground mb-3",children:[(0,a.jsxs)("div",{className:"flex items-center",children:[(0,a.jsx)(l.A,{className:"h-3 w-3 mr-1"}),(0,a.jsx)("span",{children:i.agency})]}),(0,a.jsxs)("div",{className:"flex items-center",children:[(0,a.jsx)(c.A,{className:"h-3 w-3 mr-1"}),(0,a.jsx)("span",{children:i.period})]}),(0,a.jsxs)("div",{className:"flex items-center",children:[(0,a.jsx)(d.A,{className:"h-3 w-3 mr-1"}),(0,a.jsx)("span",{children:i.organizations.join(", ")})]})]}),(0,a.jsx)("p",{className:"text-muted-foreground",children:i.description})]}),i.link&&(0,a.jsxs)(s(),{href:i.link,className:"inline-flex items-center text-sm font-medium text-primary hover:text-primary/80 transition-colors",children:["View Project Details",(0,a.jsx)(h.A,{className:"ml-1 h-3 w-3"})]})]})]})}function g(){return(0,a.jsx)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6",children:[...p].sort((e,i)=>i.id-e.id).map((e,i)=>(0,a.jsx)(m,{project:e,index:i},e.id))})}},3227:(e,i,t)=>{"use strict";t.d(i,{A:()=>a});let a=(0,t(9946).A)("Building2",[["path",{d:"M6 22V4a2 2 0 0 1 2-2h8a2 2 0 0 1 2 2v18Z",key:"1b4qmf"}],["path",{d:"M6 12H4a2 2 0 0 0-2 2v6a2 2 0 0 0 2 2h2",key:"i71pzd"}],["path",{d:"M18 9h2a2 2 0 0 1 2 2v9a2 2 0 0 1-2 2h-2",key:"10jefs"}],["path",{d:"M10 6h4",key:"1itunk"}],["path",{d:"M10 10h4",key:"tcdvrf"}],["path",{d:"M10 14h4",key:"kelpxr"}],["path",{d:"M10 18h4",key:"1ulq68"}]])},3786:(e,i,t)=>{"use strict";t.d(i,{A:()=>a});let a=(0,t(9946).A)("ExternalLink",[["path",{d:"M15 3h6v6",key:"1q9fwt"}],["path",{d:"M10 14 21 3",key:"gplh6r"}],["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}]])},7580:(e,i,t)=>{"use strict";t.d(i,{A:()=>a});let a=(0,t(9946).A)("Users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["path",{d:"M16 3.13a4 4 0 0 1 0 7.75",key:"1da9ce"}]])},9074:(e,i,t)=>{"use strict";t.d(i,{A:()=>a});let a=(0,t(9946).A)("Calendar",[["path",{d:"M8 2v4",key:"1cmpym"}],["path",{d:"M16 2v4",key:"4m81vk"}],["rect",{width:"18",height:"18",x:"3",y:"4",rx:"2",key:"1hopcy"}],["path",{d:"M3 10h18",key:"8toen8"}]])},9263:(e,i,t)=>{Promise.resolve().then(t.bind(t,325))}},e=>{var i=i=>e(e.s=i);e.O(0,[632,766,874,441,684,358],()=>i(9263)),_N_E=e.O()}]);